{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://datahack.analyticsvidhya.com/contest/mckinsey-analytics-online-hackathon-4/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 1 \n",
    "--\n",
    "Level 1 models: Uses 8 orginal features and three derived features to build Decision Tree, Random Forest, Boosted trees (XGBoost) and Logistic regression (balanced by class weights). Tried SVM and KNN, they take too long to fine tune.\n",
    "\n",
    "Ensemble model: Hyper-parameter tuned XGBoost model with all the original features, 5 derived features and level 1 predictions as inputs. \n",
    "\n",
    "Part 2\n",
    "--\n",
    "Basin hopping for optimization of the cost function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1 - Predicting Insurance Renewal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.base import TransformerMixin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"/home/sanjay/Downloads/chk/train_ZoGVYWq.csv\")\n",
    "test = pd.read_csv(\"/home/sanjay/Downloads/chk/test_66516Ee.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing indicator variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Count_missing'] = np.where(train['Count_3-6_months_late'].isnull(), 'yes', 'no')\n",
    "test['Count_missing'] = np.where(test['Count_3-6_months_late'].isnull(), 'yes', 'no')\n",
    "train['application_underwriting_score_missing'] = np.where(train['application_underwriting_score'].isnull(), 'yes', 'no')\n",
    "test['application_underwriting_score_missing'] = np.where(test['application_underwriting_score'].isnull(), 'yes', 'no')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Perc_3-6_months_late'] = train['Count_3-6_months_late']/train['no_of_premiums_paid']\n",
    "train['Perc_6-12_months_late'] = train['Count_6-12_months_late']/train['no_of_premiums_paid']\n",
    "train['Perc_more_than_12_months_late'] = train['Count_more_than_12_months_late']/train['no_of_premiums_paid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['Perc_3-6_months_late'] = test['Count_3-6_months_late']/test['no_of_premiums_paid']\n",
    "test['Perc_6-12_months_late'] = test['Count_6-12_months_late']/test['no_of_premiums_paid']\n",
    "test['Perc_more_than_12_months_late'] = test['Count_more_than_12_months_late']/test['no_of_premiums_paid']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_cols = set(train.columns) - set(['renewal','id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = list(set(list(train._get_numeric_data())).intersection(selected_cols))\n",
    "categorical_cols = list(selected_cols - set(numeric_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class DFMissingNum(TransformerMixin):\n",
    "    '''\n",
    "    Replaces missing values by input value or method.Below are the methods available. \n",
    "    'mean': replace missing values using the mean.\n",
    "    'median': replace missing values using the median\n",
    "    'most_frequent': replace missing values using the mode\n",
    "    'backfill' or 'bfill': use NEXT valid observation to fill gap.\n",
    "    'pad' or 'ffill': propagate last valid observation forward to next valid.\n",
    "    Numeric value: Replaces with the input value\n",
    "    Ex: repalce = \"\"mean\"\" for replacing with mean, replace = 0 for replacing with the numeric 0\n",
    "    Note: No quotes for numeric values\n",
    "    '''\n",
    "    def __init__(self,replace):\n",
    "        self.replace = replace\n",
    "        self.imp = None\n",
    "        self.statistics_ = None        \n",
    "        \n",
    "    def fit(self,X,y=None): \n",
    "         \n",
    "        if type(self.replace) == dict:\n",
    "            for key, value in self.replace.iteritems():\n",
    "                if value in ['mean','median','most_frequent']:\n",
    "                    self.replace[key] = _Impute(value= value,S=X[key])\n",
    "            \n",
    "        elif self.replace in ['mean','median','most_frequent']:\n",
    "            self.imp = DFImputer(strategy=self.replace)\n",
    "            self.imp.fit(X)\n",
    "            self.statistics_ = pd.Series(self.imp.statistics_, index=X.columns)\n",
    "        return self    \n",
    "    \n",
    "    def transform(self,X):\n",
    "        if self.replace in ['mean','median','most_frequent']:\n",
    "            Ximp = self.imp.transform(X)\n",
    "            X_replaced = pd.DataFrame(Ximp, index=X.index, columns=X.columns)\n",
    "        \n",
    "        elif self.replace in ['backfill','bfill','pad','ffill']:\n",
    "            X_replaced = X.fillna(method=self.replace)\n",
    "        \n",
    "        elif type(self.replace) == dict:\n",
    "            X_replaced = X.copy()\n",
    "            for key, value in self.replace.iteritems():\n",
    "                if value in ['backfill','bfill','pad','ffill']:\n",
    "                    X_replaced[key] = X_replaced[key].fillna(method=value)\n",
    "                else:\n",
    "                    X_replaced[key] = X_replaced[key].fillna(value=value)\n",
    "        else:\n",
    "            X_replaced = X.fillna(value=self.replace)\n",
    "        return X_replaced\n",
    "\n",
    "class DFMissingStr(TransformerMixin):\n",
    "    '''\n",
    "    METHODS\n",
    "    most_frequent:\n",
    "    backfill/bfill:\n",
    "    pad/ffill:\n",
    "    '''\n",
    "    def __init__(self,replace):\n",
    "        self.replace = replace\n",
    "        self.statistics_ = None\n",
    "    def fit(self,X,y=None):\n",
    "        \n",
    "        if type(self.replace) == dict:\n",
    "            for key, value in self.replace.iteritems():\n",
    "                if value == 'most_frequent':\n",
    "                    self.replace[key] = X[key].mode()[0]\n",
    "        elif self.replace =='most_frequent':\n",
    "            self.statistics_= X.mode().to_dict()\n",
    "            for key,value in self.statistics_.items():\n",
    "                self.statistics_[key] = value.values()[0]\n",
    "\n",
    "        return self    \n",
    "    def transform(self,X):\n",
    "        if self.replace == 'most_frequent':\n",
    "            X_replaced= X.fillna(self.statistics_)\n",
    "        \n",
    "        elif self.replace in ['backfill','bfill','pad','ffill']:\n",
    "            X_replaced = X.fillna(method=self.replace)\n",
    "            \n",
    "        elif type(self.replace) == dict:\n",
    "            X_replaced = X.copy()\n",
    "            for key, value in self.replace.iteritems():\n",
    "                if value in ['backfill','bfill','pad','ffill']:\n",
    "                    X_replaced[key] = X_replaced[key].fillna(method=value)\n",
    "                else:\n",
    "                    X_replaced[key] = X_replaced[key].fillna(value=value)\n",
    "        else:\n",
    "            X_replaced = X.fillna(value=self.replace)\n",
    "        return X_replaced\n",
    "\n",
    "class DFOneHot(TransformerMixin):\n",
    "    '''\n",
    "    dummy_na: Unseeen values Boolean\n",
    "    reference - https://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html\n",
    "    '''\n",
    "    \n",
    "    def __init__(self,dummy_na=False):\n",
    "        self.dummy_na=dummy_na\n",
    "        self.categories_ = {}\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        for col in list(X):\n",
    "            self.categories_[col] = X[col].unique()\n",
    "        return self\n",
    "    \n",
    "    def transform(self,X):\n",
    "        X_new = X.copy()\n",
    "        for colname, levels in self.categories_.iteritems():\n",
    "            X_new[colname][~X_new[colname].isin(levels)] = np.NaN\n",
    "        X_dummy = pd.get_dummies(X_new,dummy_na=self.dummy_na)\n",
    "        \n",
    "        fit_colnames = []\n",
    "        for colname, levels in self.categories_.iteritems():\n",
    "            for level in levels:\n",
    "                fit_colnames.append(str(colname)+'_'+str(level))\n",
    "        \n",
    "        X_dummy = X_dummy.reindex(columns= fit_colnames, fill_value= 0)\n",
    "        \n",
    "        return X_dummy\n",
    "\n",
    "\n",
    "class ColumnExtractor(TransformerMixin):\n",
    "\n",
    "    def __init__(self, cols):\n",
    "        self.cols = cols\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        # stateless transformer\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        # assumes X is a DataFrame\n",
    "        Xcols = pd.DataFrame(X[self.cols])\n",
    "        return Xcols\n",
    "\n",
    "class DFFeatureUnion(TransformerMixin):\n",
    "    # FeatureUnion but for pandas DataFrames\n",
    "\n",
    "    def __init__(self, transformer_list):\n",
    "        self.transformer_list = transformer_list\n",
    "        print \"Feature union successfully initiated.\"\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        for (name, t) in self.transformer_list:\n",
    "            t.fit(X, y)\n",
    "\n",
    "        print \"Feature union - successful fit.\"\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        # assumes X is a DataFrame\n",
    "        Xts = [t.transform(X) for _, t in self.transformer_list]\n",
    "        Xunion = reduce(lambda X1, X2: pd.merge(X1, X2, left_index=True, right_index=True), Xts)\n",
    "        print \"Feature union - successful transform.\"\n",
    "        return Xunion\n",
    "\n",
    "from sklearn.preprocessing import Imputer\n",
    "class DFImputer(TransformerMixin):\n",
    "    # Imputer but for pandas DataFrames\n",
    "\n",
    "    def __init__(self, strategy='mean'):\n",
    "        self.strategy = strategy\n",
    "        self.imp = None\n",
    "        self.statistics_ = None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.imp = Imputer(strategy=self.strategy)\n",
    "        self.imp.fit(X)\n",
    "        self.statistics_ = pd.Series(self.imp.statistics_, index=X.columns)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        # assumes X is a DataFrame\n",
    "        Ximp = self.imp.transform(X)\n",
    "        Xfilled = pd.DataFrame(Ximp, index=X.index, columns=X.columns)\n",
    "        return Xfilled\n",
    "\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature union successfully initiated.\n",
      "Feature union - successful fit.\n",
      "Feature union - successful transform.\n",
      "Feature union - successful transform.\n"
     ]
    }
   ],
   "source": [
    "preprocess = Pipeline([(\"features\",DFFeatureUnion([\n",
    "    (\"numeric\",Pipeline([(\"num_sel\",ColumnExtractor(numeric_cols)),(\"num_impute\",DFMissingNum(replace='median'))])),\n",
    "    (\"categorical\",Pipeline([(\"cat_sel\",ColumnExtractor(categorical_cols)),(\"str_impute\",DFMissingStr(replace='most_frequent')),(\"one_hot\",DFOneHot())]))\n",
    "]))])\n",
    "\n",
    "raw_train = preprocess.fit_transform(train)\n",
    "\n",
    "raw_test = preprocess.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selected based on feature importance from a baseline model\n",
    "round1_features = ['age_in_days',\n",
    "'Income',\n",
    "'application_underwriting_score',\n",
    "'perc_premium_paid_by_cash_credit',\n",
    "'no_of_premiums_paid',\n",
    "'Count_3-6_months_late',\n",
    "'Count_6-12_months_late',\n",
    "'Count_more_than_12_months_late',\n",
    "'Perc_3-6_months_late',\n",
    "'Perc_6-12_months_late',\n",
    "'Perc_more_than_12_months_late']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_train = raw_train[round1_features]\n",
    "processed_test = raw_test[round1_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = processed_train.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train['renewal']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "tree_cls = DecisionTreeClassifier(max_depth=2)\n",
    "# scores = cross_val_score(tree_cls, X, y, scoring='roc_auc', cv=10)\n",
    "# print(\"AUC: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=2,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_cls.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for name, importance in zip(processed_train.columns, tree_cls.feature_importances_):\n",
    "#     print(name, importance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# rf_cls = RandomForestClassifier(max_depth=2, random_state=0, class_weight=\"balanced\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scores = cross_val_score(rf_cls, X, y, scoring='roc_auc', cv=10)\n",
    "# print(\"AUC: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_cls = RandomForestClassifier(**{'bootstrap': True,\n",
    " 'max_depth': 2,\n",
    " 'max_features': 'sqrt',\n",
    " 'min_samples_leaf': 2,\n",
    " 'min_samples_split': 5,\n",
    " 'n_estimators': 200})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scores = cross_val_score(rf_cls, X, y, scoring='roc_auc', cv=10)\n",
    "# print(\"AUC: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=2, max_features='sqrt', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=2, min_samples_split=5,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_cls.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for name, importance in zip(processed_train.columns, rf_cls.feature_importances_):\n",
    "#     print(name, importance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boosted Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "xgb_cls = XGBClassifier(max_depth=3, n_estimators=200)\n",
    "\n",
    "# scores = cross_val_score(xgb_cls, X, y, scoring='roc_auc', cv=10)\n",
    "# print(\"AUC: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=200,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_cls.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for name, importance in zip(processed_train.columns, xgb_cls.feature_importances_):\n",
    "#     print(name, importance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logistic_cls = LogisticRegression(class_weight=\"balanced\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_cls.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scores = cross_val_score(logistic_cls, X, y, scoring='roc_auc', cv=10)\n",
    "# print(\"AUC: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM Classifier -- takes too long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# svm_cls = SVC(class_weight=\"balanced\", probability=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scores = cross_val_score(svm_cls, X, y, scoring='roc_auc', cv=3)\n",
    "# print(\"AUC: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tree_cls.fit(X,y)\n",
    "tree_predictions_train = [x[1] for x in tree_cls.predict_proba(processed_train.values)]\n",
    "tree_predictions_test = [x[1] for x in tree_cls.predict_proba(processed_test.values)]\n",
    "\n",
    "# rf_cls.fit(X,y)\n",
    "rf_predictions_train = [x[1] for x in rf_cls.predict_proba(processed_train.values)]\n",
    "rf_predictions_test = [x[1] for x in rf_cls.predict_proba(processed_test.values)]\n",
    "\n",
    "# xgb_cls.fit(X, y)\n",
    "xgb_predictions_train = [x[1] for x in xgb_cls.predict_proba(processed_train.values)]\n",
    "xgb_predictions_test = [x[1] for x in xgb_cls.predict_proba(processed_test.values)]\n",
    "\n",
    "# logistic_cls.fit(X,y)\n",
    "logistic_predictions_train = [x[1] for x in logistic_cls.predict_proba(processed_train.values)]\n",
    "logistic_predictions_test = [x[1] for x in logistic_cls.predict_proba(processed_test.values)]\n",
    "\n",
    "# svm_cls.fit(X,y)\n",
    "# svm_predictions_train = [x[1] for x in svm_cls.predict_proba(processed_train.values)]\n",
    "# svm_predictions_test = [x[1] for x in svm_cls.predict_proba(processed_test.values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_train['tree_pred'] = tree_predictions_train\n",
    "raw_train['rf_pred'] = rf_predictions_train\n",
    "raw_train['xgb_pred'] = xgb_predictions_train\n",
    "raw_train['logistic_pred'] = logistic_predictions_train\n",
    "# raw_train['svm_pred'] = svm_predictions_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "raw_test['tree_pred'] = tree_predictions_test\n",
    "raw_test['rf_pred'] = rf_predictions_test\n",
    "raw_test['xgb_pred'] = xgb_predictions_test\n",
    "raw_test['logistic_pred'] = logistic_predictions_test\n",
    "# raw_test['svm_pred'] = svm_predictions_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_train.to_csv('/home/sanjay/Downloads/chk/train_after_ens_sat.csv', index= False)\n",
    "raw_test.to_csv('/home/sanjay/Downloads/chk/test_after_ens_sat.csv', index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = raw_train.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.86 (+/- 0.01)\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(xgb_cls, X, y, scoring='roc_auc', cv=10)\n",
    "print(\"AUC: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.85925073, 0.86298945, 0.84715896, 0.86313425, 0.86382821,\n",
       "       0.84973707, 0.85820668, 0.86121136, 0.85579415, 0.84354721])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Iterative process - tune alpha (first model was overfitting); fix learning rate; try more complex model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 9 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  8.9min\n",
      "[Parallel(n_jobs=-1)]: Done  90 out of  90 | elapsed: 18.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.857145 using {'reg_alpha': 5}\n",
      "0.856959 (0.008124) with: {'reg_alpha': 0.01}\n",
      "0.856970 (0.008124) with: {'reg_alpha': 0.1}\n",
      "0.856995 (0.008052) with: {'reg_alpha': 0.5}\n",
      "0.856945 (0.008106) with: {'reg_alpha': 0.8}\n",
      "0.856962 (0.008213) with: {'reg_alpha': 1}\n",
      "0.857073 (0.008166) with: {'reg_alpha': 1.5}\n",
      "0.857115 (0.008200) with: {'reg_alpha': 2}\n",
      "0.857145 (0.008234) with: {'reg_alpha': 5}\n",
      "0.857119 (0.008316) with: {'reg_alpha': 10}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# grid search - alpha\n",
    "model = XGBClassifier(max_depth=4, n_estimators=400, learning_rate=0.01)\n",
    "# n_estimators = [50, 100, 150, 200]\n",
    "# max_depth = [2, 4, 6, 8]\n",
    "reg_alpha=[1e-2, 0.1, 0.5, 0.8, 1, 1.5, 2, 5, 10]\n",
    "\n",
    "param_grid = dict(reg_alpha=reg_alpha)\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=7)\n",
    "grid_search = GridSearchCV(model, param_grid, n_jobs=-1, cv=kfold, verbose=1, scoring='roc_auc')\n",
    "grid_result = grid_search.fit(X, y)\n",
    "\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'reg_alpha': 5}"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_result.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=200,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=1, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_cls = XGBClassifier(max_depth=3, n_estimators=200, reg_alpha=1)\n",
    "xgb_cls.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.86 (+/- 0.01)\n"
     ]
    }
   ],
   "source": [
    "xgb_cls = XGBClassifier(max_depth=3, n_estimators=400, reg_alpha=1, learning_rate=0.01)\n",
    "scores = cross_val_score(xgb_cls, X, y, scoring='roc_auc', cv=10)\n",
    "print(\"AUC: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 20 candidates, totalling 200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed: 35.3min\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed: 40.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.856962 using {'n_estimators': 400, 'max_depth': 4}\n",
      "0.837788 (0.014289) with: {'n_estimators': 50, 'max_depth': 2}\n",
      "0.842172 (0.009454) with: {'n_estimators': 100, 'max_depth': 2}\n",
      "0.850623 (0.007930) with: {'n_estimators': 150, 'max_depth': 2}\n",
      "0.853883 (0.008437) with: {'n_estimators': 200, 'max_depth': 2}\n",
      "0.856314 (0.008258) with: {'n_estimators': 400, 'max_depth': 2}\n",
      "0.853347 (0.007586) with: {'n_estimators': 50, 'max_depth': 4}\n",
      "0.855450 (0.007739) with: {'n_estimators': 100, 'max_depth': 4}\n",
      "0.856421 (0.007928) with: {'n_estimators': 150, 'max_depth': 4}\n",
      "0.856787 (0.008123) with: {'n_estimators': 200, 'max_depth': 4}\n",
      "0.856962 (0.008213) with: {'n_estimators': 400, 'max_depth': 4}\n",
      "0.853638 (0.007860) with: {'n_estimators': 50, 'max_depth': 6}\n",
      "0.855744 (0.007910) with: {'n_estimators': 100, 'max_depth': 6}\n",
      "0.856326 (0.007952) with: {'n_estimators': 150, 'max_depth': 6}\n",
      "0.856485 (0.007921) with: {'n_estimators': 200, 'max_depth': 6}\n",
      "0.856037 (0.008348) with: {'n_estimators': 400, 'max_depth': 6}\n",
      "0.853480 (0.007849) with: {'n_estimators': 50, 'max_depth': 8}\n",
      "0.855365 (0.008361) with: {'n_estimators': 100, 'max_depth': 8}\n",
      "0.856006 (0.008139) with: {'n_estimators': 150, 'max_depth': 8}\n",
      "0.856038 (0.008158) with: {'n_estimators': 200, 'max_depth': 8}\n",
      "0.855124 (0.008502) with: {'n_estimators': 400, 'max_depth': 8}\n"
     ]
    }
   ],
   "source": [
    "# grid search - tree parameters\n",
    "model = XGBClassifier(reg_alpha=1, learning_rate=0.01)\n",
    "n_estimators = [50, 100, 150, 200, 400]\n",
    "max_depth = [2, 4, 6, 8]\n",
    "# reg_alpha=[1e-5, 1e-2, 0.1, 1, 100]\n",
    "\n",
    "param_grid = dict(n_estimators=n_estimators, max_depth=max_depth)\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=7)\n",
    "grid_search = GridSearchCV(model, param_grid, n_jobs=-1, cv=kfold, verbose=1, scoring='roc_auc')\n",
    "grid_result = grid_search.fit(X, y)\n",
    "\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.01, max_delta_step=0,\n",
       "       max_depth=4, min_child_weight=1, missing=None, n_estimators=400,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=5, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_cls = XGBClassifier(max_depth=4, n_estimators=400, reg_alpha=5, learning_rate=0.01)\n",
    "xgb_cls.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sanjay/code/.virtualenvs/impact/local/lib/python2.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/sanjay/code/.virtualenvs/impact/lib/python2.7/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "predictions = xgb_cls.predict_proba(raw_test.values)\n",
    "predictions_val = xgb_cls.predict(raw_test.values)\n",
    "\n",
    "final_predictions = [x[1] for x in predictions]\n",
    "\n",
    "processed_test['id'] = test['id']\n",
    "df_out = raw_test.copy()\n",
    "df_out['renewal'] = final_predictions\n",
    "df_out['guess'] = predictions_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out.to_csv('/home/sanjay/Downloads/chk/predictions_baseline_new_sat_2.csv', index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Perc_more_than_12_months_late</th>\n",
       "      <th>premium</th>\n",
       "      <th>age_in_days</th>\n",
       "      <th>Perc_3-6_months_late</th>\n",
       "      <th>application_underwriting_score</th>\n",
       "      <th>Count_6-12_months_late</th>\n",
       "      <th>Income</th>\n",
       "      <th>Count_more_than_12_months_late</th>\n",
       "      <th>Count_3-6_months_late</th>\n",
       "      <th>perc_premium_paid_by_cash_credit</th>\n",
       "      <th>...</th>\n",
       "      <th>sourcing_channel_D</th>\n",
       "      <th>sourcing_channel_E</th>\n",
       "      <th>application_underwriting_score_missing_no</th>\n",
       "      <th>application_underwriting_score_missing_yes</th>\n",
       "      <th>tree_pred</th>\n",
       "      <th>rf_pred</th>\n",
       "      <th>xgb_pred</th>\n",
       "      <th>logistic_pred</th>\n",
       "      <th>renewal</th>\n",
       "      <th>guess</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3300.0</td>\n",
       "      <td>27384.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>99.89</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51150.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.974798</td>\n",
       "      <td>0.963705</td>\n",
       "      <td>0.992822</td>\n",
       "      <td>0.884125</td>\n",
       "      <td>0.985690</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>11700.0</td>\n",
       "      <td>23735.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>98.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>285140.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.124</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.974798</td>\n",
       "      <td>0.963705</td>\n",
       "      <td>0.983847</td>\n",
       "      <td>0.765156</td>\n",
       "      <td>0.978429</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>11700.0</td>\n",
       "      <td>17170.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>99.21</td>\n",
       "      <td>0.0</td>\n",
       "      <td>186030.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.888877</td>\n",
       "      <td>0.922661</td>\n",
       "      <td>0.811631</td>\n",
       "      <td>0.456192</td>\n",
       "      <td>0.728201</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5400.0</td>\n",
       "      <td>16068.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>99.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>123540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.198</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.974798</td>\n",
       "      <td>0.963021</td>\n",
       "      <td>0.974434</td>\n",
       "      <td>0.718838</td>\n",
       "      <td>0.967882</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>9600.0</td>\n",
       "      <td>10591.0</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>99.17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>200020.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.041</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.974798</td>\n",
       "      <td>0.954307</td>\n",
       "      <td>0.967848</td>\n",
       "      <td>0.582151</td>\n",
       "      <td>0.967647</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Perc_more_than_12_months_late  premium  age_in_days  Perc_3-6_months_late  \\\n",
       "0                            0.0   3300.0      27384.0              0.000000   \n",
       "1                            0.0  11700.0      23735.0              0.000000   \n",
       "2                            0.0  11700.0      17170.0              0.000000   \n",
       "3                            0.0   5400.0      16068.0              0.000000   \n",
       "4                            0.0   9600.0      10591.0              0.071429   \n",
       "\n",
       "   application_underwriting_score  Count_6-12_months_late    Income  \\\n",
       "0                           99.89                     0.0   51150.0   \n",
       "1                           98.93                     0.0  285140.0   \n",
       "2                           99.21                     0.0  186030.0   \n",
       "3                           99.00                     0.0  123540.0   \n",
       "4                           99.17                     0.0  200020.0   \n",
       "\n",
       "   Count_more_than_12_months_late  Count_3-6_months_late  \\\n",
       "0                             0.0                    0.0   \n",
       "1                             0.0                    0.0   \n",
       "2                             0.0                    0.0   \n",
       "3                             0.0                    0.0   \n",
       "4                             0.0                    1.0   \n",
       "\n",
       "   perc_premium_paid_by_cash_credit  ...    sourcing_channel_D  \\\n",
       "0                             0.001  ...                     0   \n",
       "1                             0.124  ...                     0   \n",
       "2                             1.000  ...                     0   \n",
       "3                             0.198  ...                     0   \n",
       "4                             0.041  ...                     0   \n",
       "\n",
       "   sourcing_channel_E  application_underwriting_score_missing_no  \\\n",
       "0                   0                                          1   \n",
       "1                   0                                          1   \n",
       "2                   0                                          0   \n",
       "3                   0                                          1   \n",
       "4                   0                                          1   \n",
       "\n",
       "   application_underwriting_score_missing_yes  tree_pred   rf_pred  xgb_pred  \\\n",
       "0                                           0   0.974798  0.963705  0.992822   \n",
       "1                                           0   0.974798  0.963705  0.983847   \n",
       "2                                           1   0.888877  0.922661  0.811631   \n",
       "3                                           0   0.974798  0.963021  0.974434   \n",
       "4                                           0   0.974798  0.954307  0.967848   \n",
       "\n",
       "   logistic_pred   renewal  guess  \n",
       "0       0.884125  0.985690      1  \n",
       "1       0.765156  0.978429      1  \n",
       "2       0.456192  0.728201      1  \n",
       "3       0.718838  0.967882      1  \n",
       "4       0.582151  0.967647      1  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_out.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2 - Optimizing Agent Incentives "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import exp\n",
    "import numpy as np\n",
    "def total_revenue(incentive_array, predicted_df=df_out):\n",
    "    delta_p_array = [0.2*(1-exp(-(10*(1-exp(-incentive/400)))/5)) for incentive in incentive_array]\n",
    "    predicted_df['incentive'] = incentive_array\n",
    "    predicted_df['delta_p'] = delta_p_array\n",
    "    predicted_df['revenue'] = predicted_df.apply(lambda row: row['guess']*(row['incentive'] - (row['delta_p']*row['premium']))\n",
    "                                                 , axis=1)\n",
    "    return predicted_df['revenue'].sum(), np.asarray(predicted_df['revenue'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def positive_numbers(**kwargs):\n",
    "    x = kwargs['x_new']\n",
    "    tmax = True\n",
    "    tmin = bool(np.all(x >= 0))\n",
    "    return tmax and tmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "incentive_list = pd.read_csv(\"/home/sanjay/Downloads/chk/submission_baseline_sat_1pm.csv\")['incentives'].tolist()\n",
    "guess_list = df_out['guess'].tolist()\n",
    "incentive_array = np.asarray([a*b for a,b in zip(incentive_list,guess_list)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global minimum: -356061831.141\n"
     ]
    }
   ],
   "source": [
    "from scipy.optimize import basinhopping\n",
    "minimizer_kwargs = {\"method\":\"L-BFGS-B\", \"jac\":True}\n",
    "ret = basinhopping(total_revenue, incentive_array, minimizer_kwargs=minimizer_kwargs, stepsize=100,\n",
    "                   niter=200, accept_test=positive_numbers,seed=123)\n",
    "\n",
    "assured_revenue = df_out.apply(lambda row: (row['renewal']*row['premium']), axis=1).sum()\n",
    "print(\"global minimum: {}\".format(ret.fun-assured_revenue))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "347623000.1753256"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assured_revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out['incentives'] = ret.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out['id'] = test['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_submission = df_out[['id','renewal','incentives']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>renewal</th>\n",
       "      <th>incentives</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>649</td>\n",
       "      <td>0.985690</td>\n",
       "      <td>1527.428930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>81136</td>\n",
       "      <td>0.978429</td>\n",
       "      <td>2163.968908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70762</td>\n",
       "      <td>0.728201</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53935</td>\n",
       "      <td>0.967882</td>\n",
       "      <td>1612.129802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15476</td>\n",
       "      <td>0.967647</td>\n",
       "      <td>1232.456119</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id   renewal   incentives\n",
       "0    649  0.985690  1527.428930\n",
       "1  81136  0.978429  2163.968908\n",
       "2  70762  0.728201     0.000000\n",
       "3  53935  0.967882  1612.129802\n",
       "4  15476  0.967647  1232.456119"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_submission.to_csv('/home/sanjay/Downloads/chk/submission_baseline_sat_3pm.csv', index= False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
